{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Materi7_NaturalLanguangeProcessing(NLP)Dasar.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMTBWsVCCYpXzcNNzTB9fQi",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ditamaylani/PSDS_KelasMahir_PejuangData3.0/blob/main/Materi7_NaturalLanguangeProcessing(NLP)Dasar.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KgAIEh8G60kb"
      },
      "source": [
        "# **Natural Language Processing (NLP) Dasar**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CeMcPqfH7SUS"
      },
      "source": [
        "Pada pertemuan ini kamu akan belajar:\n",
        "*  Apa itu NLP\n",
        "*  Scrapping Data\n",
        "*  Text Preprocessing\n",
        "  * Case Folding & Data Cleaning\n",
        "  * Lemmatisasi\n",
        "  * Stemming\n",
        "  * Slang Word\n",
        "  * Stop Word\n",
        "  * Unwanted Word\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OnJBrQpH8N3G"
      },
      "source": [
        "**Import Library**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HAQyusG88VMs"
      },
      "source": [
        "import sys  # Modul sys digunakan untuk mengakses konfigurasi interpreter pada saat runtime dan berinteraksi dengan environment sistem operasi.\n",
        "if not sys.warnoptions:\n",
        "  import warnings\n",
        "  warnings.simplefilter(\"ignore\")"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QriOpmOl6-Yw"
      },
      "source": [
        "## **Apa itu NLP ?**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vvSWZisQ81ym"
      },
      "source": [
        "Natural Language Processing (NLP) merupakan salah satu cabang ilmu AI (*Artificial Intelligence*) yang berfokus pada pengolahan bahasa natural. Bahasa natural adalah bahasa yang secara umum digunakan oleh manusia dalam berkomunikasi satu sama lain. Bahasa yang diterima oleh komputer butuh untuk diproses dan dipahami terlebih dahulu supaya maksud dari user bisa dipahami dengan baik oleh komputer."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EswqsQ8a8-ON"
      },
      "source": [
        "Ada berbagai terapan aplikasi dari NLP. Diantaranya adalah Chatbot (aplikasi yang membuat user bisa seolah-olah melakukan komunikasi dengan computer), Stemming atau Lemmatization (pemotongan kata dalam bahasa tertentu menjadi bentuk dasar pengenalan fungsi setiap kata dalam kalimat), Summarization (ringkasan dari bacaan), Translation Tools (menterjemahkan bahasa) dan aplikasi-aplikasi lain yang memungkinkan komputer mampu memahami instruksi bahasa yang diinputkan oleh user."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ytQmMfa69EI3"
      },
      "source": [
        "Pustejovsky dan Stubbs (2012) menjelaskan bahwa ada beberapa area utama penelitian pada field NLP, diantaranya:\n",
        "1.  **Question Answering Systems (QAS)**. Kemampuan komputer untuk menjawab pertanyaan yang\n",
        "diberikan oleh user. Daripada memasukkan keyword ke dalam browser pencarian, dengan QAS, user bisa\n",
        "langsung bertanya dalam bahasa natural yang digunakannya, baik itu Inggris, Mandarin, ataupun\n",
        "Indonesia.\n",
        "2. **Summarization**. Pembuatan ringkasan dari sekumpulan konten dokumen atau email. Dengan\n",
        "menggunakan aplikasi ini, user bisa dibantu untuk mengkonversikan dokumen teks yang besar ke dalam\n",
        "bentuk slide presentasi. Machine Translation. Produk yang dihasilkan adalah aplikasi yang dapat\n",
        "memahami bahasa manusia dan menterjemahkannya ke dalam bahasa lain. Termasuk di dalamnya adalah\n",
        "Google Translate yang apabila dicermati semakin membaik dalam penterjemahan bahasa. Contoh lain lagi\n",
        "adalah BabelFish yang menterjemahkan bahasa pada real time.\n",
        "3.  **Speech Recognition**. Field ini merupakan cabang ilmu NLP yang cukup sulit. Proses pembangunan\n",
        "model untuk digunakan telpon/komputer dalam mengenali bahasa yang diucapkan sudah banyak\n",
        "dikerjakan. Bahasa yang sering digunakan adalah berupa pertanyaan dan perintah.\n",
        "4. **Document classification**. Sedangkan aplikasi ini adalah merupakan area penelitian NLP Yang paling\n",
        "sukses. Pekerjaan yang dilakukan aplikasi ini adalah menentukan dimana tempat terbaik dokumen yang\n",
        "baru diinputkan ke dalam sistem. Hal ini sangat berguna pada aplikasi spam filtering, news article\n",
        "classification, dan movie review.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QFacVLhU7E5J"
      },
      "source": [
        "## **Scrapping Data**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p5t_AKXeBKdm"
      },
      "source": [
        "Sebelum melakukan penerapan dan berbagai penelitian. Mengumpulkan data teks sebagai bahan dasar dari\n",
        "bidang ini merupakan hal yang sangat penting. Proses ini biasa disebut dengan scrapping data. Aktivitas\n",
        "scrapping data bisa dilakukan melalui berbagai platfrom. Mulai langsung pada halaman web tertentu, melalui\n",
        "API seperti Twitter, atau melalui tools yang sudah disediakan, bisa free atau berbayar. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rEM5xGH3Bex-"
      },
      "source": [
        "**Import Library**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y8qTtbJHBleQ"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import re # Library untuk teks preprocessing\n"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sDyRm8xeE5F1"
      },
      "source": [
        "**Menggunakan Data Tweet Sentiment Pilkada DKI 2017**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "id": "QfrQz99xE6fq",
        "outputId": "6209a1fe-bc93-4d1c-d687-60aea0d4da77"
      },
      "source": [
        "df = pd.read_csv('https://raw.githubusercontent.com/ditamaylani/dataset/main/dataset_tweet_sentiment_pilkada_DKI_2017.csv')\n",
        "df"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Id</th>\n",
              "      <th>Sentiment</th>\n",
              "      <th>Pasangan Calon</th>\n",
              "      <th>Text Tweet</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>negative</td>\n",
              "      <td>Agus-Sylvi</td>\n",
              "      <td>Banyak akun kloning seolah2 pendukung #agussil...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>negative</td>\n",
              "      <td>Agus-Sylvi</td>\n",
              "      <td>#agussilvy bicara apa kasihan yaa...lap itu ai...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>negative</td>\n",
              "      <td>Agus-Sylvi</td>\n",
              "      <td>Kalau aku sih gak nunggu hasil akhir QC tp lag...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>negative</td>\n",
              "      <td>Agus-Sylvi</td>\n",
              "      <td>Kasian oh kasian dengan peluru 1milyar untuk t...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>negative</td>\n",
              "      <td>Agus-Sylvi</td>\n",
              "      <td>Maaf ya pendukung #AgusSilvy..hayo dukung #Ani...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>895</th>\n",
              "      <td>896</td>\n",
              "      <td>positive</td>\n",
              "      <td>Anies-Sandi</td>\n",
              "      <td>Kali saja bpk @aniesbaswedan @sandiuno lihat, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>896</th>\n",
              "      <td>897</td>\n",
              "      <td>positive</td>\n",
              "      <td>Anies-Sandi</td>\n",
              "      <td>Kita harus dapat merangkul semua orang tanpa b...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>897</th>\n",
              "      <td>898</td>\n",
              "      <td>positive</td>\n",
              "      <td>Anies-Sandi</td>\n",
              "      <td>Ini jagoanku dibidang digital &lt;Smiling Face Wi...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>898</th>\n",
              "      <td>899</td>\n",
              "      <td>positive</td>\n",
              "      <td>Anies-Sandi</td>\n",
              "      <td>#PesanBijak #OkeOce #GubernurGu3 ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>899</th>\n",
              "      <td>900</td>\n",
              "      <td>positive</td>\n",
              "      <td>Anies-Sandi</td>\n",
              "      <td>Sandiaga: Bangun Rumah DP 0% Lebih Simpel Diba...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>900 rows × 4 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      Id  ...                                         Text Tweet\n",
              "0      1  ...  Banyak akun kloning seolah2 pendukung #agussil...\n",
              "1      2  ...  #agussilvy bicara apa kasihan yaa...lap itu ai...\n",
              "2      3  ...  Kalau aku sih gak nunggu hasil akhir QC tp lag...\n",
              "3      4  ...  Kasian oh kasian dengan peluru 1milyar untuk t...\n",
              "4      5  ...  Maaf ya pendukung #AgusSilvy..hayo dukung #Ani...\n",
              "..   ...  ...                                                ...\n",
              "895  896  ...  Kali saja bpk @aniesbaswedan @sandiuno lihat, ...\n",
              "896  897  ...  Kita harus dapat merangkul semua orang tanpa b...\n",
              "897  898  ...  Ini jagoanku dibidang digital <Smiling Face Wi...\n",
              "898  899  ...               #PesanBijak #OkeOce #GubernurGu3 ...\n",
              "899  900  ...  Sandiaga: Bangun Rumah DP 0% Lebih Simpel Diba...\n",
              "\n",
              "[900 rows x 4 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ndon1XgYFG20"
      },
      "source": [
        "**Mengambil Series Data Teks Tweet**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LqARi5fHFJZz",
        "outputId": "dbb205f5-840d-4399-f5b7-3ce864ae266a"
      },
      "source": [
        "tweet=df['Text Tweet']\n",
        "tweet"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0      Banyak akun kloning seolah2 pendukung #agussil...\n",
              "1      #agussilvy bicara apa kasihan yaa...lap itu ai...\n",
              "2      Kalau aku sih gak nunggu hasil akhir QC tp lag...\n",
              "3      Kasian oh kasian dengan peluru 1milyar untuk t...\n",
              "4      Maaf ya pendukung #AgusSilvy..hayo dukung #Ani...\n",
              "                             ...                        \n",
              "895    Kali saja bpk @aniesbaswedan @sandiuno lihat, ...\n",
              "896    Kita harus dapat merangkul semua orang tanpa b...\n",
              "897    Ini jagoanku dibidang digital <Smiling Face Wi...\n",
              "898                 #PesanBijak #OkeOce #GubernurGu3 ...\n",
              "899    Sandiaga: Bangun Rumah DP 0% Lebih Simpel Diba...\n",
              "Name: Text Tweet, Length: 900, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ieiriCJb7KMg"
      },
      "source": [
        "## **Text Preprocessing**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jASljP9fCHol"
      },
      "source": [
        "Setelah mendapat data teks. Salah satu tantangan dari data teks adalah bentuknya yang sangat beragam.\n",
        "Sebuah kata dapat ditulis dengan berbagai bentuk. Kemudian juga besar sekali kemungkinan adalah\n",
        "kesalahan penulisan. Tanda baca, angka, dan lain-lain. Oleh sebab itu, sebelum diolah lebih lanjut untuk\n",
        "diproses menjadi data numerik, maka diperlukan pemrosesan data teks agar menjadi bentuk yang lebih bersih\n",
        "dan standar. Yang akan sangat mempengaruhi hasil analisis data teks tersebut. Pada sentimen analisis\n",
        "misalnya, langkah ini menjadi sangat penting. Ada beberapa hal yang dilakukan pada tahap Teks\n",
        "Preprocessing:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kgc4sVF57sNl"
      },
      "source": [
        "### **1. Case Folding & Data Cleaning**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qH9WmHgzCN87"
      },
      "source": [
        "Case folding adalah salah satu bentuk text preprocessing yang paling sederhana dan efektif meskipun sering\n",
        "diabaikan. Tujuan dari case folding untuk mengubah semua huruf dalam dokumen menjadi huruf kecil. Hanya\n",
        "huruf ‘a’ sampai ‘z’ yang diterima. Karakter selain huruf dihilangkan dan dianggap delimiter.\n",
        "\n",
        "\n",
        "Ada beberapa cara yang dapat digunakan dalam tahap case folding, diantaranya:\n",
        "\n",
        "*  Menghapus tanda baca\n",
        "*  Menghapus angka\n",
        "*  Mengubah text menjadi lowercase\n",
        "*  Menghapus whitepace (karakter kosong) "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 137
        },
        "id": "AKSJUAN6FsD4",
        "outputId": "c1ffdc40-3fda-4aa0-fc9a-b4ddd407c5ba"
      },
      "source": [
        "# Menghapus tanda baca\n",
        "print(tweet[103])\n",
        "tweet[103]=re.sub(r'[^\\w]|_',' ', tweet[103])\n",
        "tweet[103]"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Buat pendukung #AHY mari rapatkan barisan ke paslon #3 Buang issu miring paslon #3 Masih mau dipimpin seorang TERDAKWA? SIMULUT EMBER????\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  This is separate from the ipykernel package so we can avoid doing imports until\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Buat pendukung  AHY mari rapatkan barisan ke paslon  3 Buang issu miring paslon  3 Masih mau dipimpin seorang TERDAKWA  SIMULUT EMBER    '"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 222
        },
        "id": "EIAzrECsGfEG",
        "outputId": "be640064-e2b8-4d38-da07-826559d4ee60"
      },
      "source": [
        "# Menghapus angka\n",
        "print(tweet[103])\n",
        "tweet[103] = re.sub(\"\\S*\\d\\S*\", \"\", tweet[103]).strip()\n",
        "tweet[103] = re.sub(r\"\\b\\d+\\b\", \" \", tweet[103])\n",
        "tweet[103]"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Buat pendukung  AHY mari rapatkan barisan ke paslon  3 Buang issu miring paslon  3 Masih mau dipimpin seorang TERDAKWA  SIMULUT EMBER    \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  This is separate from the ipykernel package so we can avoid doing imports until\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  after removing the cwd from sys.path.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Buat pendukung  AHY mari rapatkan barisan ke paslon   Buang issu miring paslon   Masih mau dipimpin seorang TERDAKWA  SIMULUT EMBER'"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 137
        },
        "id": "3VzetGmHCuSy",
        "outputId": "2afc077a-4086-4e94-bbf0-ab900043048d"
      },
      "source": [
        "#Mengubah text menjadi lowercase\n",
        "print(tweet[103])\n",
        "tweet[103]=tweet[103].lower()\n",
        "tweet[103]"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Buat pendukung  AHY mari rapatkan barisan ke paslon   Buang issu miring paslon   Masih mau dipimpin seorang TERDAKWA  SIMULUT EMBER\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  This is separate from the ipykernel package so we can avoid doing imports until\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'buat pendukung  ahy mari rapatkan barisan ke paslon   buang issu miring paslon   masih mau dipimpin seorang terdakwa  simulut ember'"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 137
        },
        "id": "i1vXxsaaCws3",
        "outputId": "be66c921-4408-490d-f47b-72c9d1e6fe4e"
      },
      "source": [
        "# Menghapus white space\n",
        "print(tweet[103])\n",
        "tweet[103]=re.sub('[\\s]+', ' ', tweet[103])\n",
        "tweet[103]"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "buat pendukung  ahy mari rapatkan barisan ke paslon   buang issu miring paslon   masih mau dipimpin seorang terdakwa  simulut ember\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  This is separate from the ipykernel package so we can avoid doing imports until\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'buat pendukung ahy mari rapatkan barisan ke paslon buang issu miring paslon masih mau dipimpin seorang terdakwa simulut ember'"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pfgu3pFKC3By"
      },
      "source": [
        "Membuat Fungsi untuk Melakukan Case Folding"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UoVZiaAvC862"
      },
      "source": [
        "import re, string, unicodedata\n",
        "def Case_Folding(text):\n",
        "    # Hapus non-ascii\n",
        "    text = unicodedata.normalize('NFKD', text).encode('ascii', 'ignore').decode('utf-8', 'ignore')\n",
        " \n",
        "    # Menghapus Tanda Baca\n",
        "    text = re.sub(r'[^\\w]|_',' ', text)\n",
        " \n",
        "    # Menghapus Angka\n",
        "    text = re.sub(\"\\S*\\d\\S*\", \"\", text).strip()\n",
        "    text = re.sub(r\"\\b\\d+\\b\", \" \", text)\n",
        " \n",
        "    # Mengubah text menjadi lowercase\n",
        "    text = text.lower()\n",
        " \n",
        "    # Menghapus white space\n",
        "    text = re.sub('[\\s]+', ' ', text)\n",
        " \n",
        "    return text"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_jN6rKHK7y2U"
      },
      "source": [
        "### **2. Lemmatisasi**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HO5DDiEbDOay"
      },
      "source": [
        "Proses pengurangan berbagai bentuk kata yang berubah menjadi satu bentuk untuk memudahkan analisis. e.g.\n",
        "kata dari “swim”, “swimming”, “swims”, “swam”, adalah semua bentuk dari “swim”. Nah jadi lemma dari semua\n",
        "kata-kata tersebut adalah “swim”.\n",
        "\n",
        "\n",
        "Untuk data teks berbahasa Indonesia, kita akan menggunakan library `nlp-id` . Pertama kita harus\n",
        "menginstallnya terlebih dahulu.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ksBEfipDfA67",
        "outputId": "f69a8b3d-aa14-4215-e467-bc9c9e023c10"
      },
      "source": [
        "!pip install nlp-id"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting nlp-id\n",
            "  Downloading nlp_id-0.1.12.0.tar.gz (7.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 7.9 MB 15.1 MB/s \n",
            "\u001b[?25hCollecting scikit-learn==0.22\n",
            "  Downloading scikit_learn-0.22-cp37-cp37m-manylinux1_x86_64.whl (7.0 MB)\n",
            "\u001b[K     |████████████████████████████████| 7.0 MB 42.8 MB/s \n",
            "\u001b[?25hCollecting nltk==3.4.5\n",
            "  Downloading nltk-3.4.5.zip (1.5 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.5 MB 42.6 MB/s \n",
            "\u001b[?25hCollecting wget==3.2\n",
            "  Downloading wget-3.2.zip (10 kB)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from nltk==3.4.5->nlp-id) (1.15.0)\n",
            "Requirement already satisfied: scipy>=0.17.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn==0.22->nlp-id) (1.4.1)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn==0.22->nlp-id) (1.1.0)\n",
            "Requirement already satisfied: numpy>=1.11.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn==0.22->nlp-id) (1.19.5)\n",
            "Building wheels for collected packages: nlp-id, nltk, wget\n",
            "  Building wheel for nlp-id (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for nlp-id: filename=nlp_id-0.1.12.0-py3-none-any.whl size=8074105 sha256=debe53a841896b45b9c28545278be816cd2f489c7bcafc34d049d7068d69ad22\n",
            "  Stored in directory: /root/.cache/pip/wheels/b2/50/48/da59531125bd94f48dfe66140f41d8fd8a4f04062050375013\n",
            "  Building wheel for nltk (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for nltk: filename=nltk-3.4.5-py3-none-any.whl size=1449924 sha256=e6586bdef824152479baa823e3d6b069a8c94aabcc1081284da3c012ca3c3ebc\n",
            "  Stored in directory: /root/.cache/pip/wheels/48/8b/7f/473521e0c731c6566d631b281f323842bbda9bd819eb9a3ead\n",
            "  Building wheel for wget (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for wget: filename=wget-3.2-py3-none-any.whl size=9672 sha256=70e40d505c0771b3dcdc2b902d09f4429aef6293a520c8b0afdbe04eb3794f44\n",
            "  Stored in directory: /root/.cache/pip/wheels/a1/b6/7c/0e63e34eb06634181c63adacca38b79ff8f35c37e3c13e3c02\n",
            "Successfully built nlp-id nltk wget\n",
            "Installing collected packages: wget, scikit-learn, nltk, nlp-id\n",
            "  Attempting uninstall: scikit-learn\n",
            "    Found existing installation: scikit-learn 0.22.2.post1\n",
            "    Uninstalling scikit-learn-0.22.2.post1:\n",
            "      Successfully uninstalled scikit-learn-0.22.2.post1\n",
            "  Attempting uninstall: nltk\n",
            "    Found existing installation: nltk 3.2.5\n",
            "    Uninstalling nltk-3.2.5:\n",
            "      Successfully uninstalled nltk-3.2.5\n",
            "Successfully installed nlp-id-0.1.12.0 nltk-3.4.5 scikit-learn-0.22 wget-3.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "APCFu9yYfN47"
      },
      "source": [
        "Kemudian kita akan menggunakan fungsi `Lemmatizer()` untuk melakukan lemmatisasi data teks."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 137
        },
        "id": "tFDnYHFhDgse",
        "outputId": "783e31d3-50e5-4810-d21a-5957b771d236"
      },
      "source": [
        "from nlp_id.lemmatizer import Lemmatizer\n",
        "lemmatizer = Lemmatizer() \n",
        "print(tweet[103])\n",
        "tweet[103]=lemmatizer.lemmatize(tweet[103]) \n",
        "tweet[103]"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "buat pendukung ahy mari rapatkan barisan ke paslon buang issu miring paslon masih mau dipimpin seorang terdakwa simulut ember\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  after removing the cwd from sys.path.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'buat dukung ahy mari rapat baris ke paslon buang issu miring paslon masih mau pimpin orang dakwa simulut ember'"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yClEHESA73sh"
      },
      "source": [
        "### **3. Stemming**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0cHOHg47DwfZ"
      },
      "source": [
        "Stemming merupakan suatu proses untuk menemukan kata dasar dari sebuah kata. Dengan menghilangkan\n",
        "semua imbuhan (affixes) baik yang terdiri dari awalan (prefixes), sisipan (infixes), akhiran (suffixes) dan\n",
        "confixes (kombinasi dari awalan dan akhiran) pada kata turunan. Stemming digunakan untuk mengganti bentuk\n",
        "dari suatu kata menjadi kata dasar dari kata tersebut yang sesuai dengan struktur morfologi Bahasa Indonesia\n",
        "yang baik dan benar.\n",
        "\n",
        "\n",
        "Untuk data teks berbahasa Indonesia, kita akan menggunakan library PySastrawi . Pertama kita harus\n",
        "menginstallnya terlebih dahulu.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D8gp1IM6gGNg",
        "outputId": "b09e4057-6db2-44c9-ee0d-47e87aea6833"
      },
      "source": [
        "!pip install PySastrawi"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting PySastrawi\n",
            "  Downloading PySastrawi-1.2.0-py2.py3-none-any.whl (210 kB)\n",
            "\u001b[?25l\r\u001b[K     |█▋                              | 10 kB 20.7 MB/s eta 0:00:01\r\u001b[K     |███▏                            | 20 kB 27.2 MB/s eta 0:00:01\r\u001b[K     |████▊                           | 30 kB 32.3 MB/s eta 0:00:01\r\u001b[K     |██████▎                         | 40 kB 27.9 MB/s eta 0:00:01\r\u001b[K     |███████▉                        | 51 kB 22.5 MB/s eta 0:00:01\r\u001b[K     |█████████▍                      | 61 kB 23.5 MB/s eta 0:00:01\r\u001b[K     |███████████                     | 71 kB 23.6 MB/s eta 0:00:01\r\u001b[K     |████████████▌                   | 81 kB 24.8 MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 92 kB 25.1 MB/s eta 0:00:01\r\u001b[K     |███████████████▋                | 102 kB 26.7 MB/s eta 0:00:01\r\u001b[K     |█████████████████▏              | 112 kB 26.7 MB/s eta 0:00:01\r\u001b[K     |██████████████████▊             | 122 kB 26.7 MB/s eta 0:00:01\r\u001b[K     |████████████████████▎           | 133 kB 26.7 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▉          | 143 kB 26.7 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▍        | 153 kB 26.7 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 163 kB 26.7 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▌     | 174 kB 26.7 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████    | 184 kB 26.7 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▋  | 194 kB 26.7 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▏| 204 kB 26.7 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 210 kB 26.7 MB/s \n",
            "\u001b[?25hInstalling collected packages: PySastrawi\n",
            "Successfully installed PySastrawi-1.2.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-rKnPMfKgAgf"
      },
      "source": [
        "Kemudian kita akan menggunakan fungsi `StemmerFactory()` untuk melakukan stemming."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 137
        },
        "id": "9DZ-csYwEBG7",
        "outputId": "3cad437b-9c29-4bd6-917a-5bad5834b9bd"
      },
      "source": [
        "from Sastrawi.Stemmer.StemmerFactory import StemmerFactory\n",
        "\n",
        "# Membuat stemmer\n",
        "factory = StemmerFactory()\n",
        "stemmer = factory.create_stemmer()\n",
        "print(tweet[290])\n",
        "\n",
        "tweet[290] = stemmer.stem(tweet[290])\n",
        "tweet[290]\n"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mas #Agus Tetap Semangat . Pendukung #Ahy Jangan Tidur . #Basuki Maju Terus InsyaAllah Menang\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:8: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'mas agus tetap semangat dukung ahy jangan tidur basuki maju terus insyaallah menang'"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BfxBQqxb77R3"
      },
      "source": [
        "### **4. Slang Word**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xaLBYX9fEO3v"
      },
      "source": [
        "Slang adalah kata-kata yang tidak baku secara bahasa namun sering dipakai oleh pengguna bahasa. Kita perlu\n",
        "melakukan standarisasi untuk slang."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cAMV40P6EYxQ"
      },
      "source": [
        "slang_dictionary = pd.read_csv('https://raw.githubusercontent.com/nikovs/data-science-portfolio/master/topic%20modelling/colloquial-indonesian-lexicon.csv')\n",
        "slang_dict = pd.Series(slang_dictionary['formal'].values,index=slang_dictionary['slang']).to_dict()\n"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4qQnVHupEbJo"
      },
      "source": [
        "def Slangwords(text):\n",
        " for word in text.split():\n",
        "   if word in slang_dict.keys():\n",
        "     text = text.replace(word, slang_dict[word])\n",
        " return text"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7kq0cMAAEf3t",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 137
        },
        "outputId": "e905dfc2-ca11-43db-a108-63fc78669379"
      },
      "source": [
        "print(tweet[350])\n",
        "\n",
        "tweet[350]=Slangwords(tweet[350]) \n",
        "tweet[350]"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "habiburokhman sindir #Ahok via #puisi #Sembako http://obsessionnews.com #AniesSandiGubernurKita #AhokDjarot #Aniesâ€¦ https://twitter.com\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  This is separate from the ipykernel package so we can avoid doing imports until\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'habiburokhman sindir #Ahok via #puisi #Sembako http://obsessionnews.com #AniesSandiGubernurKita #AhokDjarot #Aniesâ€¦ https://twitter.com'"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PanFRHql7_PL"
      },
      "source": [
        "### **5. Stop Word**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3JTvE3XMENqw"
      },
      "source": [
        "Stop words adalah kata umum (common words) yang biasanya muncul dalam jumlah besar dan dianggap tidak\n",
        "memiliki makna. Stop words umumnya dimanfaatkan dalam task information retrieval, termasuk oleh Google\n",
        "(penjelasannya di sini). Contoh stop words untuk bahasa Inggris diantaranya “of”, “the”. Sedangkan untuk\n",
        "bahasa Indonesia diantaranya “yang”, “di”, “ke”.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0E5pmUAFFHP0"
      },
      "source": [
        "from nlp_id.stopword import StopWord\n",
        "stopword = StopWord() "
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 137
        },
        "id": "SfPVfcfTFJdp",
        "outputId": "3e9cf29e-348f-4e30-a2a0-998e868beede"
      },
      "source": [
        "from nlp_id.stopword import StopWord\n",
        "print(tweet[399])\n",
        "\n",
        "tweet[399]=stopword.remove_stopword(tweet[399])\n",
        "tweet[399]"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sederhana aja kan? Ya orang yang mempertanyakan soal susah move on berarti cuma yang sok skeptis dan tim kontra Ahok #AhokDjarot\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  after removing the cwd from sys.path.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Sederhana? orang susah move on sok skeptis tim kontra Ahok#AhokDjarot'"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l2e5gLqC8C8s"
      },
      "source": [
        "### **6. Unwated Word**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iC7qdpFSFN_h"
      },
      "source": [
        "Unwanted words adalah kata-kata yang berada di luar beberapa hal di atas namun perlu untuk kita hapus. Kita\n",
        "bisa mendefinisikan sendiri kata-kata atau karakter yang ingin kita hilangkan dari data teks yang kita peroleh."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iOAqsyHa6l3s"
      },
      "source": [
        "unwanted_words = ['sy', 'karna', 'gue', 'pun', 'nya', 'yg', 'gw', 'ke', 'gak', 'ga', 'buat'\n",
        " 'gue', 'dampak', 'tau', 'banget', 'mohon', 'dii', 'kalo', 'dll', 'kadang',\n",
        " 'cuman', 'cuma', 'biar', 'an', 'kayak', 'dar', 'bikin', 'ssaja', 'sih',\n",
        " 'diin', 'serba', 'ampun', 'untuj', 'deh', 'jd', 'ku', 'total', 'lg', 'arti'\n",
        " 'kali', 'dasar', 'tiada', 'indonesia', 'pas', 'tidiak', 'the', 'http',\n",
        " 'dr', 'aja', 'klo', 'tp', 'gitu', 'udh', 'min', 'halo', 'tidak', 'bisa',\n",
        " 'masih', 'mau', 'kok', 'belum', 'buat', 'atau', 'sama', 'gak', 'ga', 'udah'\n",
        " 'atau', 'belum', 'ini', 'tp', 'ke', 'ya', 'itu', 'aja', 'saja', 'juga',\n",
        " 'mypertamina', 'maaf', 'gk', 'tdk', 'trus', 'jg', 'nih', 'sdh', 'mulu',\n",
        " 'gmn', 'sih', 'bs', 'suruh', 'tolong', 'dah', 'bagus', 'my', 'pertamina', \n",
        " 'engenggak', 'pakai', 'bilang', 'mending', 'hasil', 'orang', 'muncul']\n"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RGIevtJoFVsd",
        "outputId": "08606d68-09e9-4c21-ffaa-db63ac7a107a"
      },
      "source": [
        "import nltk\n",
        "from nltk import word_tokenize, sent_tokenize\n",
        "nltk.download('punkt')\n",
        "\n",
        "def RemoveUnwantedwords(text):\n",
        "    word_tokens = word_tokenize(text)\n",
        "    filtered_sentence = [word for word in word_tokens if not word in unwanted_words]\n",
        "    return ' '.join(filtered_sentence)\n"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 137
        },
        "id": "rigdk461FaH5",
        "outputId": "4239e08a-df37-44fe-85c9-62c0c2bf4255"
      },
      "source": [
        "print(tweet[700])\n",
        "\n",
        "tweet[700]=RemoveUnwantedwords(tweet[700])\n",
        "tweet[700]"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ahok menistakan agama untuk menang pilkada - Logika timses @aniesbaswedan #MataNajwaDebatJakarta #salambersama #okeoce\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  This is separate from the ipykernel package so we can avoid doing imports until\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Ahok menistakan agama untuk menang pilkada - Logika timses @ aniesbaswedan # MataNajwaDebatJakarta # salambersama # okeoce'"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "46njZJ3xFjVt"
      },
      "source": [
        "### **Menerapkan Semua Langkah**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 504
        },
        "id": "jdeOlm--FrVv",
        "outputId": "4a46ff51-d1b9-4012-f4b1-cb101893976d"
      },
      "source": [
        "df['Tidy Tweet'] = ''\n",
        "for i, row in df.iterrows():\n",
        "    content = tweet[i]\n",
        "    result = Case_Folding(content)\n",
        "    result = lemmatizer.lemmatize(result)\n",
        "    result = stemmer.stem(result)\n",
        "    result = Slangwords(result)\n",
        "    result = stopword.remove_stopword(result)\n",
        "    result = RemoveUnwantedwords(result)\n",
        "    df['Tidy Tweet'][i] = result\n",
        "df[['Text Tweet', 'Tidy Tweet']]"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:10: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  # Remove the CWD from sys.path while we load stuff.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Text Tweet</th>\n",
              "      <th>Tidy Tweet</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Banyak akun kloning seolah2 pendukung #agussil...</td>\n",
              "      <td>akun kloning dukung agussilvy serang paslon an...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>#agussilvy bicara apa kasihan yaa...lap itu ai...</td>\n",
              "      <td>agussilvy bicara kasihan lap air mata wkwkwkwk</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Kalau aku sih gak nunggu hasil akhir QC tp lag...</td>\n",
              "      <td>enggak memenunggu qc memenunggu motif cuit sby...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Kasian oh kasian dengan peluru 1milyar untuk t...</td>\n",
              "      <td>kasihh oh kasihh peluru rw agussilvy mempan me...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Maaf ya pendukung #AgusSilvy..hayo dukung #Ani...</td>\n",
              "      <td>dukung agussilvy hayo dukung aniessandi putar ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>895</th>\n",
              "      <td>Kali saja bpk @aniesbaswedan @sandiuno lihat, ...</td>\n",
              "      <td>bpk aniesbaswedan sandiuno lihat rspun selfie ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>896</th>\n",
              "      <td>Kita harus dapat merangkul semua orang tanpa b...</td>\n",
              "      <td>rangkul batas usia kelamin okeoce ok hand sala...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>897</th>\n",
              "      <td>Ini jagoanku dibidang digital &lt;Smiling Face Wi...</td>\n",
              "      <td>jago bidang digital smiling face with sunglass...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>898</th>\n",
              "      <td>#PesanBijak #OkeOce #GubernurGu3 ...</td>\n",
              "      <td>pesanbijak okeoce</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>899</th>\n",
              "      <td>Sandiaga: Bangun Rumah DP 0% Lebih Simpel Diba...</td>\n",
              "      <td>sandiaga bangun rumah dp simpel banding tol ci...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>900 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                            Text Tweet                                         Tidy Tweet\n",
              "0    Banyak akun kloning seolah2 pendukung #agussil...  akun kloning dukung agussilvy serang paslon an...\n",
              "1    #agussilvy bicara apa kasihan yaa...lap itu ai...     agussilvy bicara kasihan lap air mata wkwkwkwk\n",
              "2    Kalau aku sih gak nunggu hasil akhir QC tp lag...  enggak memenunggu qc memenunggu motif cuit sby...\n",
              "3    Kasian oh kasian dengan peluru 1milyar untuk t...  kasihh oh kasihh peluru rw agussilvy mempan me...\n",
              "4    Maaf ya pendukung #AgusSilvy..hayo dukung #Ani...  dukung agussilvy hayo dukung aniessandi putar ...\n",
              "..                                                 ...                                                ...\n",
              "895  Kali saja bpk @aniesbaswedan @sandiuno lihat, ...  bpk aniesbaswedan sandiuno lihat rspun selfie ...\n",
              "896  Kita harus dapat merangkul semua orang tanpa b...  rangkul batas usia kelamin okeoce ok hand sala...\n",
              "897  Ini jagoanku dibidang digital <Smiling Face Wi...  jago bidang digital smiling face with sunglass...\n",
              "898               #PesanBijak #OkeOce #GubernurGu3 ...                                  pesanbijak okeoce\n",
              "899  Sandiaga: Bangun Rumah DP 0% Lebih Simpel Diba...  sandiaga bangun rumah dp simpel banding tol ci...\n",
              "\n",
              "[900 rows x 2 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NxLiAbaty8Li"
      },
      "source": [
        "df.to_csv('Pilkada_DKI.csv',index=False)"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "co1n9uMnzFv8",
        "outputId": "88f1ca65-2075-4580-bc78-93bfa9c23d60"
      },
      "source": [
        "from google.colab import files\n",
        "files.download(\"Pilkada_DKI.csv\")"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "download(\"download_389ceccb-9fc0-4562-8190-571052d62207\", \"Pilkada_DKI.csv\", 185800)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ]
}